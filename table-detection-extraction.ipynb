{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSNAaEVg5xge"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "p-nwgmwr6yB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers easyocr pdf2image\n",
        "!apt-get install poppler-utils"
      ],
      "metadata": {
        "id": "9vPxkDe061OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForObjectDetection, TableTransformerForObjectDetection\n",
        "from torchvision import transforms\n",
        "from PIL import Image, ImageDraw\n",
        "from pdf2image import convert_from_path\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.patches import Patch\n",
        "import numpy as np\n",
        "import easyocr\n",
        "from tqdm.auto import tqdm\n",
        "import csv\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "import io\n",
        "import json\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import functional as TF\n",
        "from torchvision import transforms\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "F-ZRfulk65-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_path = ''\n",
        "\n",
        "with open(config_path, 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "pdf_path = config[\"pdf_path\"]\n",
        "csv_path = config[\"csv_path\"]\n",
        "images_path = config[\"images_path\"]\n",
        "tables_path = config[\"tables_path\"]"
      ],
      "metadata": {
        "id": "gNp76Q4O6_LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(images_path, exist_ok=True)\n",
        "os.makedirs(tables_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "XfNzwpBxDfrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detection_model = AutoModelForObjectDetection.from_pretrained(\"microsoft/table-transformer-detection\", revision=\"no_timm\")\n",
        "structure_model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-structure-recognition-v1.1-all\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "detection_model.to(device)\n",
        "structure_model.to(device)"
      ],
      "metadata": {
        "id": "rOGEW4kb7Bl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxResize(object):\n",
        "    def __init__(self, max_size=800):\n",
        "        self.max_size = max_size\n",
        "    def __call__(self, image):\n",
        "        width, height = image.size\n",
        "        current_max_size = max(width, height)\n",
        "        scale = self.max_size / current_max_size\n",
        "        resized_image = image.resize((int(round(scale*width)), int(round(scale*height))))\n",
        "        return resized_image\n",
        "\n",
        "detection_transform = transforms.Compose([\n",
        "    MaxResize(800),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "structure_transform = transforms.Compose([\n",
        "    MaxResize(1000),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "mmVd0e6S7DMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pdf_to_images(pdf_path, output_folder):\n",
        "    images = convert_from_path(pdf_path)\n",
        "    image_paths = []\n",
        "    for i, image in enumerate(images):\n",
        "        image_path = os.path.join(output_folder, f'image_{i}.jpg')\n",
        "        image.save(image_path, 'JPEG')\n",
        "        image_paths.append(image_path)\n",
        "    return image_paths\n",
        "\n",
        "image_paths = pdf_to_images(pdf_path, images_path)\n",
        "\n",
        "def load_image(image_path):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img_tensor = TF.to_tensor(img).unsqueeze(0)\n",
        "    return img, img_tensor"
      ],
      "metadata": {
        "id": "GtLtwd4jETkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def box_cxcywh_to_xyxy(x):\n",
        "    x_c, y_c, w, h = x.unbind(-1)\n",
        "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h), (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
        "    return torch.stack(b, dim=1)\n",
        "\n",
        "def rescale_bboxes(out_bbox, size):\n",
        "    img_w, img_h = size\n",
        "    b = box_cxcywh_to_xyxy(out_bbox)\n",
        "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
        "    return b\n",
        "\n",
        "id2label = detection_model.config.id2label\n",
        "id2label[len(detection_model.config.id2label)] = \"no object\"\n",
        "\n",
        "def outputs_to_objects(outputs, img_size, id2label):\n",
        "    m = outputs.logits.softmax(-1).max(-1)\n",
        "    pred_labels = list(m.indices.detach().cpu().numpy())[0]\n",
        "    pred_scores = list(m.values.detach().cpu().numpy())[0]\n",
        "    pred_bboxes = outputs['pred_boxes'].detach().cpu()[0]\n",
        "    pred_bboxes = [elem.tolist() for elem in rescale_bboxes(pred_bboxes, img_size)]\n",
        "    objects = []\n",
        "    for label, score, bbox in zip(pred_labels, pred_scores, pred_bboxes):\n",
        "        class_label = id2label[int(label)]\n",
        "        if not class_label == 'no object':\n",
        "            objects.append({'label': class_label, 'score': float(score), 'bbox': [float(elem) for elem in bbox]})\n",
        "    return objects"
      ],
      "metadata": {
        "id": "1cldlyuw7ICE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tables = []\n",
        "tables_per_page = {}\n",
        "\n",
        "for idx, image_path in enumerate(image_paths):\n",
        "    print(f\"Processing image {idx+1}/{len(image_paths)}: {image_path}\")\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    pixel_values = detection_transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = detection_model(pixel_values)\n",
        "\n",
        "    objects = outputs_to_objects(outputs, image.size, id2label)\n",
        "\n",
        "    print(f\"Detected objects in image {idx+1}: {[obj['label'] for obj in objects]}\")\n",
        "\n",
        "    if any(obj['label'] == 'table' for obj in objects):\n",
        "        tables.append((image, objects))\n",
        "        if idx+1 in tables_per_page:\n",
        "            tables_per_page[idx+1] += 1\n",
        "        else:\n",
        "            tables_per_page[idx+1] = 1\n",
        "\n",
        "        print(f\"Tables found on page {idx+1}:\")\n",
        "        for table_idx, obj in enumerate(objects):\n",
        "            if obj['label'] == 'table':\n",
        "                print(f\"Table {table_idx+1}: Bounding Box: {obj['bbox']}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"No table detected in image {idx+1}\")\n",
        "\n",
        "if not tables:\n",
        "    raise ValueError(\"No tables detected in the PDF.\")"
      ],
      "metadata": {
        "id": "XLG5wq-U7IXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objects_to_crops(img, objects, class_thresholds, padding=10):\n",
        "    table_crops = []\n",
        "    for obj in objects:\n",
        "        if obj['score'] < class_thresholds[obj['label']]:\n",
        "            continue\n",
        "\n",
        "        bbox = obj['bbox']\n",
        "        bbox_with_padding = (max(0, bbox[0] - padding),\n",
        "                             max(0, bbox[1] - padding),\n",
        "                             min(img.width, bbox[2] + padding),\n",
        "                             min(img.height, bbox[3] + padding))\n",
        "\n",
        "        cropped_img = img.crop(bbox_with_padding)\n",
        "\n",
        "        table_crops.append({'image': cropped_img, 'bbox': bbox_with_padding})\n",
        "    return table_crops"
      ],
      "metadata": {
        "id": "BZ0PZ1Sf7LTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_thresholds = {\n",
        "    'table': 0,\n",
        "    'table rotated': 0,\n",
        "    'no object': 0\n",
        "}"
      ],
      "metadata": {
        "id": "E9wnS7PPfubq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, (image, objects) in enumerate(tables):\n",
        "    print(f\"Processing tables in image {idx+1}/{len(tables)}\")\n",
        "\n",
        "    table_crops = objects_to_crops(image, objects, class_thresholds, padding=10)\n",
        "\n",
        "    for table_idx, crop_info in enumerate(table_crops):\n",
        "        cropped_img = crop_info['image']\n",
        "        bbox = crop_info['bbox']\n",
        "        cropped_img.save(f\"/content/table/table_{idx}_{table_idx}.jpg\")\n",
        "        print(f\"Segment {table_idx+1} cropped and saved.\")\n",
        "\n",
        "if not tables:\n",
        "    raise ValueError(\"No tables detected in the PDF.\")"
      ],
      "metadata": {
        "id": "J1rusFhAdYrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cell_coordinates_by_row(table_data):\n",
        "    rows = [entry for entry in table_data if entry['label'] == 'table row']\n",
        "    columns = [entry for entry in table_data if entry['label'] == 'table column']\n",
        "    rows.sort(key=lambda x: x['bbox'][1])\n",
        "    columns.sort(key=lambda x: x['bbox'][0])\n",
        "\n",
        "    def find_cell_coordinates(row, column):\n",
        "        cell_bbox = [column['bbox'][0], row['bbox'][1], column['bbox'][2], row['bbox'][3]]\n",
        "        return cell_bbox\n",
        "\n",
        "    cell_coordinates = []\n",
        "    for row in rows:\n",
        "        row_cells = []\n",
        "        for column in columns:\n",
        "            cell_bbox = find_cell_coordinates(row, column)\n",
        "            row_cells.append({'column': column['bbox'], 'cell': cell_bbox})\n",
        "        row_cells.sort(key=lambda x: x['column'][0])\n",
        "        cell_coordinates.append({'row': row['bbox'], 'cells': row_cells, 'cell_count': len(row_cells)})\n",
        "    cell_coordinates.sort(key=lambda x: x['row'][1])\n",
        "    return cell_coordinates"
      ],
      "metadata": {
        "id": "4ebIy41FjchQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader = easyocr.Reader(['en'])"
      ],
      "metadata": {
        "id": "RMOSbZ5l7oD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_ocr(cell_coordinates, cropped_table):\n",
        "    data = dict()\n",
        "    max_num_columns = 0\n",
        "    for idx, row in enumerate(tqdm(cell_coordinates)):\n",
        "        row_text = []\n",
        "        for cell in row[\"cells\"]:\n",
        "            cell_image = np.array(cropped_table.crop(cell[\"cell\"]))\n",
        "            result = reader.readtext(np.array(cell_image))\n",
        "            if result:\n",
        "                text = \" \".join([x[1] for x in result])\n",
        "                row_text.append(text)\n",
        "        if len(row_text) > max_num_columns:\n",
        "            max_num_columns = len(row_text)\n",
        "        data[idx] = row_text\n",
        "\n",
        "    for row, row_data in data.copy().items():\n",
        "        if len(row_data) != max_num_columns:\n",
        "            row_data += [\"\"] * (max_num_columns - len(row_data))\n",
        "        data[row] = row_data\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "e8dDxgYX7qwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tables(tables_path, csv_path, structure_model, device):\n",
        "    with open(csv_path, 'w', newline='') as result_file:\n",
        "        wr = csv.writer(result_file, dialect='excel')\n",
        "\n",
        "\n",
        "        table_files = [filename for filename in os.listdir(tables_path) if filename.lower().endswith('.jpg')]\n",
        "\n",
        "        for idx, table_image_filename in enumerate(table_files):\n",
        "            table_image_path = os.path.join(tables_path, table_image_filename)\n",
        "            print(f\"Processing table {idx+1}/{len(table_files)}: {table_image_path}\")\n",
        "\n",
        "            img, img_tensor = load_image(table_image_path)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = structure_model(img_tensor.to(device))\n",
        "\n",
        "            structure_id2label = structure_model.config.id2label\n",
        "            structure_id2label[len(structure_id2label)] = \"no object\"\n",
        "\n",
        "            cells = outputs_to_objects(outputs, img.size, structure_id2label)\n",
        "\n",
        "            if len(cells) == 0:\n",
        "                print(f\"No cells detected in table {idx+1}\")\n",
        "                continue\n",
        "\n",
        "            cell_coordinates = get_cell_coordinates_by_row(cells)\n",
        "\n",
        "            data = apply_ocr(cell_coordinates, img)\n",
        "\n",
        "            for row, row_text in data.items():\n",
        "                wr.writerow(row_text)\n",
        "\n",
        "            for _ in range(3):\n",
        "                wr.writerow([])\n",
        "\n",
        "            print(f\"Table {idx+1} processed successfully\")\n",
        "\n",
        "    print(\"All tables processed and data written to\", csv_path)\n",
        "\n",
        "process_tables(tables_path, csv_path, structure_model, device)"
      ],
      "metadata": {
        "id": "JxkEy9dsGmbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csv_with_empty_lines(file_path):\n",
        "    with open(file_path, newline='', encoding='utf-8-sig') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        data = []\n",
        "        for row in reader:\n",
        "            if len(row) == 0 or all(cell == '' for cell in row):\n",
        "                data.append([])\n",
        "            else:\n",
        "                data.append(row)\n",
        "    return data\n",
        "\n",
        "def save_table_as_csv(table_data, table_index, output_folder):\n",
        "    with open(f'{output_folder}/table_{table_index}.csv', 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        for row in table_data:\n",
        "            writer.writerow(row)\n",
        "\n",
        "def split_csv_into_tables(csv_file, output_folder):\n",
        "    csv_data = read_csv_with_empty_lines(csv_file)\n",
        "    table_index = 1\n",
        "    start_index = 0\n",
        "\n",
        "    for idx, row in enumerate(csv_data):\n",
        "        if len(row) == 0:\n",
        "            if idx > start_index:\n",
        "                table_data = csv_data[start_index:idx]\n",
        "                save_table_as_csv(table_data, table_index, output_folder)\n",
        "                table_index += 1\n",
        "            start_index = idx + 1\n",
        "\n",
        "    if start_index < len(csv_data):\n",
        "        table_data = csv_data[start_index:]\n",
        "        save_table_as_csv(table_data, table_index, output_folder)"
      ],
      "metadata": {
        "id": "YEpeOOXG1LyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_csv_into_tables(csv_path, tables_path)"
      ],
      "metadata": {
        "id": "s5oLo4Sa3oew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/table.zip /content/table"
      ],
      "metadata": {
        "id": "bYsTJSol5sxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/table.zip')"
      ],
      "metadata": {
        "id": "ZTPabKVt58Ua"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}